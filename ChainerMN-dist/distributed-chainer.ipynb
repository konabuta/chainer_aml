{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Chainer using Datastore\n",
    "In this tutorial, you will run a Chainer training example on the [MNIST](http://yann.lecun.com/exdb/mnist/) dataset using ChainerMN distributed training across a GPU cluster. Training data is uploaded during the notebook to Azure Blob storage and registered as \"Datastore\" in Azure Machine Learning service Workspace. You can use \"Datastore\" after this experiment to access to the data in Azure Blob storage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "* Go through the [Configuration](../../../configuration.ipynb) notebook to install the Azure Machine Learning Python SDK and create an Azure ML `Workspace`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.0.15\n"
     ]
    }
   ],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostics\n",
    "Opt-in diagnostics for better experience, quality, and security of future releases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": [
     "Diagnostics"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turning diagnostics collection on. \n"
     ]
    }
   ],
   "source": [
    "from azureml.telemetry import set_diagnostics_collection\n",
    "\n",
    "set_diagnostics_collection(send_diagnostics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize workspace\n",
    "\n",
    "Initialize a [Workspace](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspace) object from the existing workspace you created in the Prerequisites step. `Workspace.from_config()` creates a workspace object from the details stored in `config.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: azureml\n",
      "Azure region: southeastasia\n",
      "Subscription id: 9c0f91b8-eb2f-484c-979c-15848c098a6b\n",
      "Resource group: amlservice\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "\n",
    "ws = Workspace.get(name='azureml', \n",
    "                      subscription_id='9c0f91b8-eb2f-484c-979c-15848c098a6b', \n",
    "                      resource_group='amlservice'\n",
    "                   )\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create or attach existing AmlCompute\n",
    "You will need to create a [compute target](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#compute-target) for training your model. In this tutorial, we use Azure ML managed compute ([AmlCompute](https://docs.microsoft.com/azure/machine-learning/service/how-to-set-up-training-targets#amlcompute)) for our remote training compute resource. Specifically, the below code creates an `STANDARD_NC6` GPU cluster that autoscales from `0` to `4` nodes.\n",
    "\n",
    "**Creation of AmlCompute takes approximately 5 minutes.** If the AmlCompute with that name is already in your workspace, this code will skip the creation process.\n",
    "\n",
    "As with other Azure services, there are limits on certain resources (e.g. AmlCompute) associated with the Azure Machine Learning service. Please read [this article](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-manage-quotas) on the default limits and how to request more quota."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target.\n",
      "{'allocationState': 'Steady', 'allocationStateTransitionTime': '2019-02-21T02:53:37.348000+00:00', 'creationTime': '2019-02-20T14:25:23.447852+00:00', 'currentNodeCount': 2, 'errors': None, 'modifiedTime': '2019-02-20T14:25:56.236703+00:00', 'nodeStateCounts': {'idleNodeCount': 2, 'leavingNodeCount': 0, 'preemptedNodeCount': 0, 'preparingNodeCount': 0, 'runningNodeCount': 0, 'unusableNodeCount': 0}, 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'targetNodeCount': 2, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_NC6S_V3'}\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# choose a name for your cluster\n",
    "cluster_name = \"gpucluster\"\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing compute target.')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC6',\n",
    "                                                           max_nodes=4)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "    compute_target.wait_for_completion(show_output=True)\n",
    "\n",
    "# use get_status() to get a detailed status for the current AmlCompute. \n",
    "print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code creates GPU compute. If you instead want to create CPU compute, provide a different VM size to the `vm_size` parameter, such as `STANDARD_D2_V2`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model on the remote compute\n",
    "Now that we have the AmlCompute ready to go, let's run our distributed training job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a project directory\n",
    "Create a directory that will contain all the necessary code from your local machine that you will need access to on the remote resource. This includes the training script and any additional files your training script depends on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "project_folder = './chainer-distr'\n",
    "os.makedirs(project_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training script\n",
    "Now you will need to create your training script. In this tutorial, the script for distributed training of MNIST is already provided for you at `train_mnist.py`. In practice, you should be able to take any custom Chainer training script as is and run it with Azure ML without having to modify your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once your script is ready, copy the training script `train_mnist.py` into the project directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./chainer-distr/chainer_mnist.py'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.copy('chainer_mnist.py', project_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./data/mnist/test-labels.gz', <http.client.HTTPMessage at 0x117553630>)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib\n",
    "import os\n",
    "\n",
    "os.makedirs('./data/mnist', exist_ok=True)\n",
    "\n",
    "urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz', filename='./data/mnist/train-images.gz')\n",
    "urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz', filename='./data/mnist/train-labels.gz')\n",
    "urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz', filename='./data/mnist/test-images.gz')\n",
    "urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz', filename='./data/mnist/test-labels.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload MNIST data to default Blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ws.get_default_datastore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading ./data/mnist/test-images.gz\n",
      "Uploading ./data/mnist/test-labels.gz\n",
      "Uploading ./data/mnist/train-images.gz\n",
      "Uploading ./data/mnist/train-labels.gz\n",
      "Uploaded ./data/mnist/test-labels.gz, 1 files out of an estimated total of 4\n",
      "Uploaded ./data/mnist/train-labels.gz, 2 files out of an estimated total of 4\n",
      "Uploaded ./data/mnist/test-images.gz, 3 files out of an estimated total of 4\n",
      "Uploaded ./data/mnist/train-images.gz, 4 files out of an estimated total of 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_3b38643741be42a284036a1b149fc0cd"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.upload(src_dir='./data/mnist', target_path='mnist', overwrite=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Azure Portal もしくは、Storage ExplorerなどのツールからBlobにデータがアップロードされていることを確認します。\n",
    "\n",
    "\n",
    "\n",
    "<div align=\"left\"><img src= \"../images/defaultblob.png\" width=\"500\" align =\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an experiment\n",
    "Create an [Experiment](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#experiment) to track all the runs in your workspace for this distributed Chainer tutorial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment_name = 'chainer-distr'\n",
    "experiment = Experiment(ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Chainer estimator\n",
    "The Azure ML SDK's Chainer estimator enables you to easily submit Chainer training jobs for both single-node and distributed runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.dnn import Chainer\n",
    "\n",
    "script_params = {\n",
    "    '--data-folder': ds.path('mnist').as_mount()\n",
    "}\n",
    "\n",
    "\n",
    "estimator = Chainer(source_directory=project_folder,\n",
    "                    compute_target=compute_target,\n",
    "                    entry_script='chainer_mnist.py',\n",
    "                    script_params = script_params,\n",
    "                    pip_packages=['pytest'],\n",
    "                    node_count=2,\n",
    "                    process_count_per_node=1,\n",
    "                    distributed_backend='mpi',\n",
    "                    use_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code specifies that we will run our training script on `2` nodes, with one worker per node. In order to execute a distributed run using MPI, you must provide the argument `distributed_backend='mpi'`. Using this estimator with these settings, Chainer and its dependencies will be installed for you. However, if your script also uses other packages, make sure to install them via the `Chainer` constructor's `pip_packages` or `conda_packages` parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit job\n",
    "Run your experiment by submitting your estimator object. Note that this call is asynchronous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(Experiment: chainer-distr,\n",
      "Id: chainer-distr_1550718150_f9da8082,\n",
      "Type: azureml.scriptrun,\n",
      "Status: Queued)\n"
     ]
    }
   ],
   "source": [
    "run = experiment.submit(estimator)\n",
    "print(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor your run\n",
    "You can monitor the progress of the run with a Jupyter widget. Like the run submission, the widget is asynchronous and provides live updates every 10-15 seconds until the job completes. You can see that the widget automatically plots and visualizes the loss metric that we logged to the Azure ML run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2391913bfae4243ac6a19fec7b4e486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': True, 'log_level': 'INFO', 's…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: chainer-distr_1550718150_f9da8082\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: chainer-distr_1550718150_f9da8082\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'chainer-distr_1550718150_f9da8082',\n",
       " 'target': 'gpucluster',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2019-02-21T03:02:51.772775Z',\n",
       " 'endTimeUtc': '2019-02-21T03:03:57.810312Z',\n",
       " 'properties': {'azureml.runsource': 'experiment',\n",
       "  'ContentSnapshotId': 'c28211c7-a162-40df-8172-d0653af0b44c'},\n",
       " 'runDefinition': {'Script': 'chainer_mnist.py',\n",
       "  'Arguments': ['--data-folder',\n",
       "   '$AZUREML_DATAREFERENCE_280a911219fe46e49d1b50ba286a1ed7'],\n",
       "  'SourceDirectoryDataStore': 'workspaceblobstore',\n",
       "  'Framework': 0,\n",
       "  'Communicator': 5,\n",
       "  'Target': 'gpucluster',\n",
       "  'DataReferences': {'280a911219fe46e49d1b50ba286a1ed7': {'DataStoreName': 'workspaceblobstore',\n",
       "    'Mode': 'Mount',\n",
       "    'PathOnDataStore': 'mnist',\n",
       "    'PathOnCompute': None,\n",
       "    'Overwrite': False},\n",
       "   'workspaceblobstore': {'DataStoreName': 'workspaceblobstore',\n",
       "    'Mode': 'Mount',\n",
       "    'PathOnDataStore': None,\n",
       "    'PathOnCompute': None,\n",
       "    'Overwrite': False}},\n",
       "  'JobName': None,\n",
       "  'AutoPrepareEnvironment': True,\n",
       "  'MaxRunDurationSeconds': None,\n",
       "  'NodeCount': 2,\n",
       "  'Environment': {'Python': {'InterpreterPath': 'python',\n",
       "    'UserManagedDependencies': False,\n",
       "    'CondaDependencies': {'name': 'project_environment',\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults',\n",
       "        'chainer==5.1.0',\n",
       "        'cupy-cuda90',\n",
       "        'pytest']}]}},\n",
       "   'EnvironmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE',\n",
       "    'NCCL_SOCKET_IFNAME': '^docker0'},\n",
       "   'Docker': {'BaseImage': 'mcr.microsoft.com/azureml/base-gpu:0.2.1',\n",
       "    'Enabled': True,\n",
       "    'SharedVolumes': True,\n",
       "    'Preparation': None,\n",
       "    'GpuSupport': True,\n",
       "    'ShmSize': '1g',\n",
       "    'Arguments': [],\n",
       "    'BaseImageRegistry': {'Address': None,\n",
       "     'Username': None,\n",
       "     'Password': None}},\n",
       "   'Spark': {'Repositories': ['https://mmlspark.azureedge.net/maven'],\n",
       "    'Packages': [{'Group': 'com.microsoft.ml.spark',\n",
       "      'Artifact': 'mmlspark_2.11',\n",
       "      'Version': '0.12'}],\n",
       "    'PrecachePackages': True}},\n",
       "  'History': {'OutputCollection': True},\n",
       "  'Spark': {'Configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'BatchAi': {'NodeCount': 0},\n",
       "  'AmlCompute': {'Name': None,\n",
       "   'VmSize': None,\n",
       "   'VmPriority': None,\n",
       "   'RetainCluster': False,\n",
       "   'ClusterMaxNodeCount': 2},\n",
       "  'Tensorflow': {'WorkerCount': 1, 'ParameterServerCount': 1},\n",
       "  'Mpi': {'ProcessCountPerNode': 1},\n",
       "  'Hdi': {'YarnDeployMode': 2},\n",
       "  'ContainerInstance': {'Region': None, 'CpuCores': 2, 'MemoryGb': 3.5},\n",
       "  'ExposedPorts': None,\n",
       "  'PrepareEnvironment': None},\n",
       " 'logFiles': {'azureml-logs/60_control_log_rank_1.txt': 'https://azureml7674401039.blob.core.windows.net/azureml/ExperimentRun/dcid.chainer-distr_1550718150_f9da8082/azureml-logs/60_control_log_rank_1.txt?sv=2018-03-28&sr=b&sig=p0xXMR%2B0DS%2BgdaQ8RkIuUVZB94%2FK2bBJzxEWINrVi1U%3D&st=2019-02-21T02%3A57%3A39Z&se=2019-02-21T11%3A07%3A39Z&sp=r',\n",
       "  'azureml-logs/60_control_log_rank_0.txt': 'https://azureml7674401039.blob.core.windows.net/azureml/ExperimentRun/dcid.chainer-distr_1550718150_f9da8082/azureml-logs/60_control_log_rank_0.txt?sv=2018-03-28&sr=b&sig=ZAO7oQC9GUaW140V7ZP5jTJfZ%2Ft3j1N63JZIhexS1dg%3D&st=2019-02-21T02%3A57%3A39Z&se=2019-02-21T11%3A07%3A39Z&sp=r',\n",
       "  'azureml-logs/80_driver_log_rank_0.txt': 'https://azureml7674401039.blob.core.windows.net/azureml/ExperimentRun/dcid.chainer-distr_1550718150_f9da8082/azureml-logs/80_driver_log_rank_0.txt?sv=2018-03-28&sr=b&sig=PMXbLfU3DBplB6Dse8hMCTHJGuMLaivRaz0azDd7Ie0%3D&st=2019-02-21T02%3A57%3A39Z&se=2019-02-21T11%3A07%3A39Z&sp=r',\n",
       "  'azureml-logs/80_driver_log_rank_1.txt': 'https://azureml7674401039.blob.core.windows.net/azureml/ExperimentRun/dcid.chainer-distr_1550718150_f9da8082/azureml-logs/80_driver_log_rank_1.txt?sv=2018-03-28&sr=b&sig=KsKh0tNWlrU5wnnXZHPAweWLehrHEql41zl%2BAR1HYfc%3D&st=2019-02-21T02%3A57%3A39Z&se=2019-02-21T11%3A07%3A39Z&sp=r',\n",
       "  'azureml-logs/azureml.log': 'https://azureml7674401039.blob.core.windows.net/azureml/ExperimentRun/dcid.chainer-distr_1550718150_f9da8082/azureml-logs/azureml.log?sv=2018-03-28&sr=b&sig=s7wdAhpvR3DMQdJsYQACBqUt52qXGEauzPTK01u20%2BQ%3D&st=2019-02-21T02%3A57%3A40Z&se=2019-02-21T11%3A07%3A40Z&sp=r',\n",
       "  'azureml-logs/56_batchai_stderr.txt': 'https://azureml7674401039.blob.core.windows.net/azureml/ExperimentRun/dcid.chainer-distr_1550718150_f9da8082/azureml-logs/56_batchai_stderr.txt?sv=2018-03-28&sr=b&sig=G1FBDNHmEf9qydc1vWSmcpGrdiF9iC%2BXyVB7mh4J9bM%3D&st=2019-02-21T02%3A57%3A40Z&se=2019-02-21T11%3A07%3A40Z&sp=r'}}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "minxia"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "msauthor": "minxia"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

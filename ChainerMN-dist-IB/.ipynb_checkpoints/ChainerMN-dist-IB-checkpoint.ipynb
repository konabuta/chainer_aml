{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChainerMN with Infiniband サンプルコード"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure ML service Python SDK 確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.0.15\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ワークスペースへの接続\n",
    "Azure Machine Learning service の [ワークスペース](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspace) に接続します。Azureに対する認証が必要になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: azureml\n",
      "Azure region: southeastasia\n",
      "Subscription id: 9c0f91b8-eb2f-484c-979c-15848c098a6b\n",
      "Resource group: amlservice\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "\n",
    "ws = Workspace.get(name='azureml', \n",
    "                      subscription_id='9c0f91b8-eb2f-484c-979c-15848c098a6b', \n",
    "                      resource_group='amlservice'\n",
    "                   )\n",
    "#ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計算環境 Machine Learning Compute (旧Batch AI) の新規作成 or 既存環境設定\n",
    "You will need to create a [compute target](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#compute-target) to execute your training script on. In this tutorial, you create an [Azure Batch AI](https://docs.microsoft.com/azure/batch-ai/overview) cluster as your training compute resource. This code creates a cluster for you if it does not already exist in your workspace.\n",
    "\n",
    "**Creation of the cluster takes approximately 5 minutes.** If the cluster is already in your workspace this code will skip the cluster creation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target gpucluster-ib\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "batchai_cluster_name = \"gpucluster-ib\"\n",
    "vm_size = \"Standard_NC24rs_v3\"\n",
    "\n",
    "try:\n",
    "    # Check for existing cluster\n",
    "    compute_target = ComputeTarget(ws,batchai_cluster_name)\n",
    "    print('Found existing compute target ' + batchai_cluster_name)\n",
    "except:\n",
    "    # Else, create new one\n",
    "    print('Creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = vm_size,\n",
    "                                                                    vm_priority = \"lowpriority\",\n",
    "                                                                    min_nodes = 0, \n",
    "                                                                    max_nodes = 2)\n",
    "    compute_target = ComputeTarget.create(ws, batchai_cluster_name, provisioning_config)\n",
    "    # can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it will use the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## リモート環境でのモデル開発\n",
    "Now that we have the cluster ready to go, let's run our distributed training job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### プロジェクトフォルダの作成\n",
    "Create a directory that will contain all the necessary code from your local machine that you will need access to on the remote resource. This includes the training script and any additional files your training script depends on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "project_folder = './script/chainer'\n",
    "os.makedirs(project_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./script/chainer/chainer_mnist.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {project_folder}/chainer_mnist.py\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "\n",
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer import training\n",
    "from chainer.training import extensions\n",
    "\n",
    "import chainermn\n",
    "\n",
    "\n",
    "class MLP(chainer.Chain):\n",
    "\n",
    "    def __init__(self, n_units, n_out):\n",
    "        super(MLP, self).__init__(\n",
    "            # the size of the inputs to each layer will be inferred\n",
    "            l1=L.Linear(784, n_units),  # n_in -> n_units\n",
    "            l2=L.Linear(n_units, n_units),  # n_units -> n_units\n",
    "            l3=L.Linear(n_units, n_out),  # n_units -> n_out\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h1 = F.relu(self.l1(x))\n",
    "        h2 = F.relu(self.l2(h1))\n",
    "        return self.l3(h2)\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description='ChainerMN example: MNIST')\n",
    "    parser.add_argument('--batchsize', '-b', type=int, default=100,\n",
    "                        help='Number of images in each mini-batch')\n",
    "    parser.add_argument('--communicator', type=str,\n",
    "                        default='hierarchical', help='Type of communicator')\n",
    "    parser.add_argument('--epoch', '-e', type=int, default=20,\n",
    "                        help='Number of sweeps over the dataset to train')\n",
    "    parser.add_argument('--gpu', '-g', action='store_true',\n",
    "                        help='Use GPU')\n",
    "    parser.add_argument('--out', '-o', default='result',\n",
    "                        help='Directory to output the result')\n",
    "    parser.add_argument('--resume', '-r', default='',\n",
    "                        help='Resume the training from snapshot')\n",
    "    parser.add_argument('--unit', '-u', type=int, default=1000,\n",
    "                        help='Number of units')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Prepare ChainerMN communicator.\n",
    "\n",
    "    if args.gpu:\n",
    "        if args.communicator == 'naive':\n",
    "            print(\"Error: 'naive' communicator does not support GPU.\\n\")\n",
    "            exit(-1)\n",
    "        comm = chainermn.create_communicator(args.communicator)\n",
    "        device = comm.intra_rank\n",
    "    else:\n",
    "        if args.communicator != 'naive':\n",
    "            print('Warning: using naive communicator '\n",
    "                  'because only naive supports CPU-only execution')\n",
    "        comm = chainermn.create_communicator('naive')\n",
    "        device = -1\n",
    "\n",
    "    if comm.rank == 0:\n",
    "        print('==========================================')\n",
    "        print('Num process (COMM_WORLD): {}'.format(comm.size))\n",
    "        if args.gpu:\n",
    "            print('Using GPUs')\n",
    "        print('Using {} communicator'.format(args.communicator))\n",
    "        print('Num unit: {}'.format(args.unit))\n",
    "        print('Num Minibatch-size: {}'.format(args.batchsize))\n",
    "        print('Num epoch: {}'.format(args.epoch))\n",
    "        print('==========================================')\n",
    "\n",
    "    model = L.Classifier(MLP(args.unit, 10))\n",
    "    if device >= 0:\n",
    "        chainer.cuda.get_device_from_id(device).use()\n",
    "        model.to_gpu()\n",
    "\n",
    "    # Create a multi node optimizer from a standard Chainer optimizer.\n",
    "    optimizer = chainermn.create_multi_node_optimizer(\n",
    "        chainer.optimizers.Adam(), comm)\n",
    "    optimizer.setup(model)\n",
    "\n",
    "    # Split and distribute the dataset. Only worker 0 loads the whole dataset.\n",
    "    # Datasets of worker 0 are evenly split and distributed to all workers.\n",
    "    if comm.rank == 0:\n",
    "        train, test = chainer.datasets.get_mnist()\n",
    "    else:\n",
    "        train, test = None, None\n",
    "    train = chainermn.scatter_dataset(train, comm, shuffle=True)\n",
    "    test = chainermn.scatter_dataset(test, comm, shuffle=True)\n",
    "\n",
    "    train_iter = chainer.iterators.SerialIterator(train, args.batchsize)\n",
    "    test_iter = chainer.iterators.SerialIterator(test, args.batchsize,\n",
    "                                                 repeat=False, shuffle=False)\n",
    "\n",
    "    updater = training.StandardUpdater(train_iter, optimizer, device=device)\n",
    "    trainer = training.Trainer(updater, (args.epoch, 'epoch'), out=args.out)\n",
    "\n",
    "    # Create a multi node evaluator from a standard Chainer evaluator.\n",
    "    evaluator = extensions.Evaluator(test_iter, model, device=device)\n",
    "    evaluator = chainermn.create_multi_node_evaluator(evaluator, comm)\n",
    "    trainer.extend(evaluator)\n",
    "\n",
    "    # Some display and output extensions are necessary only for one worker.\n",
    "    # (Otherwise, there would just be repeated outputs.)\n",
    "    if comm.rank == 0:\n",
    "        trainer.extend(extensions.dump_graph('main/loss'))\n",
    "        trainer.extend(extensions.LogReport())\n",
    "        trainer.extend(extensions.PrintReport(\n",
    "            ['epoch', 'main/loss', 'validation/main/loss',\n",
    "             'main/accuracy', 'validation/main/accuracy', 'elapsed_time']))\n",
    "        trainer.extend(extensions.ProgressBar())\n",
    "\n",
    "    if args.resume:\n",
    "        chainer.serializers.load_npz(args.resume, trainer)\n",
    "\n",
    "    trainer.run()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment \"実験\" の作成\n",
    "[Experiment\"実験\"](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#experiment) を作成し、Chainerによるモデル学習をトラックします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment_name = 'chainermn-remote-IB'\n",
    "experiment = Experiment(ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_params = {\n",
    "    '-g': '',\n",
    "    '--communicator': 'non_cuda_aware',\n",
    "    '-o': './outputs'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.dnn import *\n",
    "\n",
    "estimator = Chainer(source_directory=project_folder,\n",
    "                      compute_target=compute_target,\n",
    "                      entry_script='chainer_mnist.py',\n",
    "                      script_params=script_params,\n",
    "                      node_count=2,\n",
    "                      process_count_per_node=2,\n",
    "                      distributed_backend='mpi',     \n",
    "                      pip_packages=['mpi4py'],\n",
    "                      use_gpu=True)\n",
    "\n",
    "estimator.run_config.environment.environment_variables['NCCL_SOCKET_IFNAME'] = 'eth0'\n",
    "estimator.run_config.environment.environment_variables['NCCL_IB_DISABLE'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ジョブの実行\n",
    "Run your experiment by submitting your estimator object. Note that this call is asynchronous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(Experiment: chainermn-remote-IB,\n",
      "Id: chainermn-remote-IB_1550723898_68697f3d,\n",
      "Type: azureml.scriptrun,\n",
      "Status: Queued)\n"
     ]
    }
   ],
   "source": [
    "run = experiment.submit(estimator)\n",
    "print(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run のモニタリング\n",
    "You can monitor the progress of the run with a Jupyter widget. Like the run submission, the widget is asynchronous and provides live updates every 10-15 seconds until the job completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e645b7c5aa5b4fc7bf3dfa08e96cb263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': True, 'log_level': 'INFO', 's…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can block until the script has completed training before running more code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: chainermn-remote-IB_1550723898_68697f3d\n",
      "\n",
      "Streaming azureml-logs/60_control_log_rank_0.txt\n",
      "================================================\n",
      "\n",
      "This is an MPI job. Rank:0\n",
      "Streaming log file azureml-logs/60_control_log_rank_0.txt\n",
      "Streaming log file azureml-logs/80_driver_log_rank_0.txt\n",
      "\n",
      "Streaming azureml-logs/80_driver_log_rank_0.txt\n",
      "===============================================\n",
      "\n",
      "==========================================\n",
      "Num process (COMM_WORLD): 4\n",
      "Using GPUs\n",
      "Using non_cuda_aware communicator\n",
      "Num unit: 1000\n",
      "Num Minibatch-size: 100\n",
      "Num epoch: 20\n",
      "==========================================\n",
      "Downloading from http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz...\n",
      "Downloading from http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz...\n",
      "Downloading from http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz...\n",
      "Downloading from http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz...\n",
      "epoch       main/loss   validation/main/loss  main/accuracy  validation/main/accuracy  elapsed_time\n",
      "\u001b[J     total [#.................................................]  3.33%\n",
      "this epoch [#################################.................] 66.67%\n",
      "       100 iter, 0 epoch / 20 epochs\n",
      "       inf iters/sec. Estimated time to finish: 0:00:00.\n",
      "\u001b[4A\n",
      "\u001b[J     total [###...............................................]  6.67%\n",
      "this epoch [################..................................] 33.33%\n",
      "       200 iter, 1 epoch / 20 epochs\n",
      "    42.555 iters/sec. Estimated time to finish: 0:01:05.797968.\n",
      "\u001b[4A\n",
      "\u001b[J     total [#####.............................................] 10.00%\n",
      "this epoch [..................................................]  0.00%\n",
      "       300 iter, 2 epoch / 20 epochs\n",
      "    52.603 iters/sec. Estimated time to finish: 0:00:51.328008.\n",
      "\u001b[4A\u001b[J     total [######............................................] 13.33%\n",
      "this epoch [#################################.................] 66.67%\n",
      "       400 iter, 2 epoch / 20 epochs\n",
      "    59.106 iters/sec. Estimated time to finish: 0:00:43.988783.\n",
      "\u001b[4A\n",
      "\u001b[J     total [########..........................................] 16.67%\n",
      "this epoch [################..................................] 33.33%\n",
      "       500 iter, 3 epoch / 20 epochs\n",
      "    61.288 iters/sec. Estimated time to finish: 0:00:40.791252.\n",
      "\u001b[4A\n",
      "\u001b[J     total [##########........................................] 20.00%\n",
      "this epoch [..................................................]  0.00%\n",
      "       600 iter, 4 epoch / 20 epochs\n",
      "    62.206 iters/sec. Estimated time to finish: 0:00:38.581784.\n",
      "\u001b[4A\u001b[J     total [###########.......................................] 23.33%\n",
      "this epoch [#################################.................] 66.67%\n",
      "       700 iter, 4 epoch / 20 epochs\n",
      "    64.133 iters/sec. Estimated time to finish: 0:00:35.863178.\n",
      "\u001b[4A\u001b[J5           0.0226697   0.0661488             0.9928         0.9805                    22.8421       \n",
      "\u001b[J     total [#############.....................................] 26.67%\n",
      "this epoch [################..................................] 33.33%\n",
      "       800 iter, 5 epoch / 20 epochs\n",
      "    64.807 iters/sec. Estimated time to finish: 0:00:33.946823.\n",
      "\u001b[4A\u001b[J6           0.019805    0.0651551             0.9942         0.9821                    24.9129       \n",
      "\u001b[J     total [###############...................................] 30.00%\n",
      "this epoch [..................................................]  0.00%\n",
      "       900 iter, 6 epoch / 20 epochs\n",
      "    65.458 iters/sec. Estimated time to finish: 0:00:32.081866.\n",
      "\u001b[4A\n",
      "this epoch [#################################.................] 66.67%\n",
      "      1000 iter, 6 epoch / 20 epochs\n",
      "    66.618 iters/sec. Estimated time to finish: 0:00:30.022113.\n",
      "\u001b[4A\u001b[J7           0.0135912   0.0801639             0.995333       0.9792                    26.9804       \n",
      "\u001b[J     total [##################................................] 36.67%\n",
      "this epoch [################..................................] 33.33%\n",
      "      1100 iter, 7 epoch / 20 epochs\n",
      "    67.112 iters/sec. Estimated time to finish: 0:00:28.310716.\n",
      "\u001b[4A\n",
      "\u001b[J     total [####################..............................] 40.00%\n",
      "this epoch [..................................................]  0.00%\n",
      "      1200 iter, 8 epoch / 20 epochs\n",
      "     67.54 iters/sec. Estimated time to finish: 0:00:26.651068.\n",
      "\u001b[4A\n",
      "this epoch [#################################.................] 66.67%\n",
      "      1300 iter, 8 epoch / 20 epochs\n",
      "    67.949 iters/sec. Estimated time to finish: 0:00:25.018832.\n",
      "\u001b[4A\u001b[J9           0.00640616  0.0774529             0.9978         0.9816                    31.145        \n",
      "\u001b[J     total [#######################...........................] 46.67%\n",
      "this epoch [################..................................] 33.33%\n",
      "      1400 iter, 9 epoch / 20 epochs\n",
      "    68.082 iters/sec. Estimated time to finish: 0:00:23.501161.\n",
      "\u001b[4A\n",
      "\u001b[J     total [#########################.........................] 50.00%\n",
      "this epoch [..................................................]  0.00%\n",
      "      1500 iter, 10 epoch / 20 epochs\n",
      "    68.182 iters/sec. Estimated time to finish: 0:00:21.999949.\n",
      "\u001b[4A\n",
      "this epoch [#################################.................] 66.67%\n",
      "      1600 iter, 10 epoch / 20 epochs\n",
      "    68.832 iters/sec. Estimated time to finish: 0:00:20.339373.\n",
      "\u001b[4A\u001b[J11          0.0106134   0.0843282             0.9964         0.9794                    35.2654       \n",
      "\u001b[J     total [############################......................] 56.67%\n",
      "this epoch [################..................................] 33.33%\n",
      "      1700 iter, 11 epoch / 20 epochs\n",
      "     68.98 iters/sec. Estimated time to finish: 0:00:18.846081.\n",
      "\u001b[4A\n",
      "\u001b[J     total [##############################....................] 60.00%\n",
      "this epoch [..................................................]  0.00%\n",
      "      1800 iter, 12 epoch / 20 epochs\n",
      "     69.04 iters/sec. Estimated time to finish: 0:00:17.381315.\n",
      "\u001b[4A\n",
      "this epoch [#################################.................] 66.67%\n",
      "      1900 iter, 12 epoch / 20 epochs\n",
      "    69.545 iters/sec. Estimated time to finish: 0:00:15.817157.\n",
      "\u001b[4A\u001b[J13          0.00778067  0.0807467             0.997667       0.982                     39.3581       \n",
      "\u001b[J     total [#################################.................] 66.67%\n",
      "this epoch [################..................................] 33.33%\n",
      "      2000 iter, 13 epoch / 20 epochs\n",
      "     69.62 iters/sec. Estimated time to finish: 0:00:14.363742.\n",
      "\u001b[4A\n",
      "\u001b[J     total [###################################...............] 70.00%\n",
      "this epoch [..................................................]  0.00%\n",
      "      2100 iter, 14 epoch / 20 epochs\n",
      "    69.661 iters/sec. Estimated time to finish: 0:00:12.919638.\n",
      "\u001b[4A\n",
      "this epoch [#################################.................] 66.67%\n",
      "      2200 iter, 14 epoch / 20 epochs\n",
      "    69.989 iters/sec. Estimated time to finish: 0:00:11.430356.\n",
      "\u001b[4A\u001b[J15          0.0087775   0.0872516             0.997133       0.9814                    43.4769       \n",
      "\u001b[J     total [######################################............] 76.67%\n",
      "this epoch [################..................................] 33.33%\n",
      "      2300 iter, 15 epoch / 20 epochs\n",
      "    70.037 iters/sec. Estimated time to finish: 0:00:09.994653.\n",
      "\u001b[4A\n",
      "\u001b[J     total [########################################..........] 80.00%\n",
      "this epoch [..................................................]  0.00%\n",
      "      2400 iter, 16 epoch / 20 epochs\n",
      "    69.987 iters/sec. Estimated time to finish: 0:00:08.572972.\n",
      "\u001b[4A\n",
      "this epoch [#################################.................] 66.67%\n",
      "      2500 iter, 16 epoch / 20 epochs\n",
      "    70.305 iters/sec. Estimated time to finish: 0:00:07.111890.\n",
      "\u001b[4A\u001b[J17          0.00233581  0.0814017             0.999333       0.9832                    47.6142       \n",
      "\u001b[J     total [###########################################.......] 86.67%\n",
      "this epoch [################..................................] 33.33%\n",
      "      2600 iter, 17 epoch / 20 epochs\n",
      "    70.328 iters/sec. Estimated time to finish: 0:00:05.687607.\n",
      "\u001b[4A\n",
      "\u001b[J     total [#############################################.....] 90.00%\n",
      "this epoch [..................................................]  0.00%\n",
      "      2700 iter, 18 epoch / 20 epochs\n",
      "     70.37 iters/sec. Estimated time to finish: 0:00:04.263162.\n",
      "\u001b[4A\u001b[J     total [##############################################....] 93.33%\n",
      "this epoch [#################################.................] 66.67%\n",
      "      2800 iter, 18 epoch / 20 epochs\n",
      "    70.582 iters/sec. Estimated time to finish: 0:00:02.833602.\n",
      "\u001b[4A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[J     total [################################################..] 96.67%\n",
      "this epoch [################..................................] 33.33%\n",
      "      2900 iter, 19 epoch / 20 epochs\n",
      "    70.581 iters/sec. Estimated time to finish: 0:00:01.416817.\n",
      "\u001b[4A\n",
      "\u001b[J     total [##################################################] 100.00%\n",
      "this epoch [..................................................]  0.00%\n",
      "      3000 iter, 20 epoch / 20 epochs\n",
      "    70.611 iters/sec. Estimated time to finish: 0:00:00.\n",
      "\u001b[4A\u001b[J\n",
      "\n",
      "The experiment completed successfully. Finalizing run...\n",
      "Cleaning up all outstanding Run operations, waiting 300.0 seconds\n",
      "1 items cleaning up...\n",
      "Cleanup took 0.10081291198730469 seconds\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: chainermn-remote-IB_1550723898_68697f3d\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'chainermn-remote-IB_1550723898_68697f3d',\n",
       " 'target': 'gpucluster-ib',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2019-02-21T04:45:38.442617Z',\n",
       " 'endTimeUtc': '2019-02-21T04:49:39.45075Z',\n",
       " 'properties': {'azureml.runsource': 'experiment',\n",
       "  'ContentSnapshotId': '25cb9c56-a461-4274-85ca-1b514a6a1ef1'},\n",
       " 'runDefinition': {'Script': 'chainer_mnist.py',\n",
       "  'Arguments': ['-g', '--communicator', 'non_cuda_aware', '-o', './outputs'],\n",
       "  'SourceDirectoryDataStore': 'workspaceblobstore',\n",
       "  'Framework': 0,\n",
       "  'Communicator': 5,\n",
       "  'Target': 'gpucluster-ib',\n",
       "  'DataReferences': {'workspaceblobstore': {'DataStoreName': 'workspaceblobstore',\n",
       "    'Mode': 'Mount',\n",
       "    'PathOnDataStore': None,\n",
       "    'PathOnCompute': None,\n",
       "    'Overwrite': False}},\n",
       "  'JobName': None,\n",
       "  'AutoPrepareEnvironment': True,\n",
       "  'MaxRunDurationSeconds': None,\n",
       "  'NodeCount': 2,\n",
       "  'Environment': {'Python': {'InterpreterPath': 'python',\n",
       "    'UserManagedDependencies': False,\n",
       "    'CondaDependencies': {'name': 'project_environment',\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults',\n",
       "        'chainer==5.1.0',\n",
       "        'cupy-cuda90',\n",
       "        'mpi4py']}]}},\n",
       "   'EnvironmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE',\n",
       "    'NCCL_SOCKET_IFNAME': 'eth0',\n",
       "    'NCCL_IB_DISABLE': '1'},\n",
       "   'Docker': {'BaseImage': 'mcr.microsoft.com/azureml/base-gpu:0.2.1',\n",
       "    'Enabled': True,\n",
       "    'SharedVolumes': True,\n",
       "    'Preparation': None,\n",
       "    'GpuSupport': True,\n",
       "    'ShmSize': '1g',\n",
       "    'Arguments': [],\n",
       "    'BaseImageRegistry': {'Address': None,\n",
       "     'Username': None,\n",
       "     'Password': None}},\n",
       "   'Spark': {'Repositories': ['https://mmlspark.azureedge.net/maven'],\n",
       "    'Packages': [{'Group': 'com.microsoft.ml.spark',\n",
       "      'Artifact': 'mmlspark_2.11',\n",
       "      'Version': '0.12'}],\n",
       "    'PrecachePackages': True}},\n",
       "  'History': {'OutputCollection': True},\n",
       "  'Spark': {'Configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'BatchAi': {'NodeCount': 0},\n",
       "  'AmlCompute': {'Name': None,\n",
       "   'VmSize': None,\n",
       "   'VmPriority': None,\n",
       "   'RetainCluster': False,\n",
       "   'ClusterMaxNodeCount': 2},\n",
       "  'Tensorflow': {'WorkerCount': 1, 'ParameterServerCount': 1},\n",
       "  'Mpi': {'ProcessCountPerNode': 2},\n",
       "  'Hdi': {'YarnDeployMode': 2},\n",
       "  'ContainerInstance': {'Region': None, 'CpuCores': 2, 'MemoryGb': 3.5},\n",
       "  'ExposedPorts': None,\n",
       "  'PrepareEnvironment': None},\n",
       " 'logFiles': {'azureml-logs/60_control_log_rank_1.txt': 'https://azureml7674401039.blob.core.windows.net/azureml/ExperimentRun/dcid.chainermn-remote-IB_1550723898_68697f3d/azureml-logs/60_control_log_rank_1.txt?sv=2018-03-28&sr=b&sig=j4L0q8oBejTxU4Pbak%2Bz7vKrFX1dJArBH%2FW3KYocOtw%3D&st=2019-02-21T04%3A39%3A40Z&se=2019-02-21T12%3A49%3A40Z&sp=r',\n",
       "  'azureml-logs/60_control_log_rank_2.txt': 'https://azureml7674401039.blob.core.windows.net/azureml/ExperimentRun/dcid.chainermn-remote-IB_1550723898_68697f3d/azureml-logs/60_control_log_rank_2.txt?sv=2018-03-28&sr=b&sig=833aR5KLW%2F%2FnRGntlbxXZY9hjK9lACCH3uhdpU1lYWw%3D&st=2019-02-21T04%3A39%3A40Z&se=2019-02-21T12%3A49%3A40Z&sp=r',\n",
       "  'azureml-logs/60_control_log_rank_3.txt': 'https://azureml7674401039.blob.core.windows.net/azureml/ExperimentRun/dcid.chainermn-remote-IB_1550723898_68697f3d/azureml-logs/60_control_log_rank_3.txt?sv=2018-03-28&sr=b&sig=IHMFam0T6vMGRE0t9Ma%2Fpv9pCsU2eZT61G448Pv401I%3D&st=2019-02-21T04%3A39%3A40Z&se=2019-02-21T12%3A49%3A40Z&sp=r',\n",
       "  'azureml-logs/60_control_log_rank_0.txt': 'https://azureml7674401039.blob.core.windows.net/azureml/ExperimentRun/dcid.chainermn-remote-IB_1550723898_68697f3d/azureml-logs/60_control_log_rank_0.txt?sv=2018-03-28&sr=b&sig=Lu1%2BKLZjS8kzpl196%2FkNUynWruJkeycRhN%2F3TyncREs%3D&st=2019-02-21T04%3A39%3A40Z&se=2019-02-21T12%3A49%3A40Z&sp=r',\n",
       "  'azureml-logs/80_driver_log_rank_0.txt': 'https://azureml7674401039.blob.core.windows.net/azureml/ExperimentRun/dcid.chainermn-remote-IB_1550723898_68697f3d/azureml-logs/80_driver_log_rank_0.txt?sv=2018-03-28&sr=b&sig=RNlAN650jREVhwD3HRJiqDkQW90MdZCwuH7kWk32f8M%3D&st=2019-02-21T04%3A39%3A40Z&se=2019-02-21T12%3A49%3A40Z&sp=r',\n",
       "  'azureml-logs/azureml.log': 'https://azureml7674401039.blob.core.windows.net/azureml/ExperimentRun/dcid.chainermn-remote-IB_1550723898_68697f3d/azureml-logs/azureml.log?sv=2018-03-28&sr=b&sig=HhkPKOw1sR0et0xtvYQonZxpsGhXMXikCTjfOs1Z%2FY8%3D&st=2019-02-21T04%3A39%3A40Z&se=2019-02-21T12%3A49%3A40Z&sp=r',\n",
       "  'azureml-logs/80_driver_log_rank_2.txt': 'https://azureml7674401039.blob.core.windows.net/azureml/ExperimentRun/dcid.chainermn-remote-IB_1550723898_68697f3d/azureml-logs/80_driver_log_rank_2.txt?sv=2018-03-28&sr=b&sig=6dWZgVZ%2Bhq8B3QxmPudoUSbd3K6XSYn6fU6CWz41yDU%3D&st=2019-02-21T04%3A39%3A40Z&se=2019-02-21T12%3A49%3A40Z&sp=r',\n",
       "  'azureml-logs/80_driver_log_rank_1.txt': 'https://azureml7674401039.blob.core.windows.net/azureml/ExperimentRun/dcid.chainermn-remote-IB_1550723898_68697f3d/azureml-logs/80_driver_log_rank_1.txt?sv=2018-03-28&sr=b&sig=8wiDlz9xczjTW4n4%2BJuhlQ5wIoRn3ZSaZXoidv6%2FNRI%3D&st=2019-02-21T04%3A39%3A40Z&se=2019-02-21T12%3A49%3A40Z&sp=r',\n",
       "  'azureml-logs/80_driver_log_rank_3.txt': 'https://azureml7674401039.blob.core.windows.net/azureml/ExperimentRun/dcid.chainermn-remote-IB_1550723898_68697f3d/azureml-logs/80_driver_log_rank_3.txt?sv=2018-03-28&sr=b&sig=X3BkiiRpQD%2BCatrTnF1pgV61v1EVrNPN9KmHLZ0Jeak%3D&st=2019-02-21T04%3A39%3A40Z&se=2019-02-21T12%3A49%3A40Z&sp=r',\n",
       "  'azureml-logs/56_batchai_stderr.txt': 'https://azureml7674401039.blob.core.windows.net/azureml/ExperimentRun/dcid.chainermn-remote-IB_1550723898_68697f3d/azureml-logs/56_batchai_stderr.txt?sv=2018-03-28&sr=b&sig=xYD6yPD4cYYUm8TXqNaKIc1IKAgeLdftp1PWXXL7w8s%3D&st=2019-02-21T04%3A39%3A40Z&se=2019-02-21T12%3A49%3A40Z&sp=r'}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.wait_for_completion(show_output=True) # this provides a verbose log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "minxia"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "msauthor": "minxia"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chainer リモート環境での学習\n",
    "\n",
    "In this tutorial, we demonstrate how to use the Azure ML Python SDK to train a Convolutional Neural Network (CNN) on a single-node GPU with Chainer to perform handwritten digit recognition on the popular MNIST dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python SDK バージョン確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.0.15\n"
     ]
    }
   ],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ワークスペースへの接続\n",
    "Azure Machine Learning service の [ワークスペース](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspace) に接続します。Azureに対する認証が必要になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Falling back to use azure cli credentials. This fall back to use azure cli credentials will be removed in the next release. \n",
      "Make sure your code doesn't require 'az login' to have happened before using azureml-sdk, except the case when you are specifying AzureCliAuthentication in azureml-sdk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: azureml\n",
      "Azure region: eastus\n",
      "Subscription id: 9c0f91b8-eb2f-484c-979c-15848c098a6b\n",
      "Resource group: dllab\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "\n",
    "ws = Workspace.get(name='azureml', \n",
    "                      subscription_id='9c0f91b8-eb2f-484c-979c-15848c098a6b', \n",
    "                      resource_group='dllab'\n",
    "                   )\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計算環境 Machine Learning Compute (旧Batch AI) の新規作成 or 既存環境設定\n",
    "You will need to create a [compute target](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#compute-target) for training your model. In this tutorial, we use Azure ML managed compute ([AmlCompute](https://docs.microsoft.com/azure/machine-learning/service/how-to-set-up-training-targets#amlcompute)) for our remote training compute resource.\n",
    "\n",
    "**Creation of AmlCompute takes approximately 5 minutes.** If the AmlCompute with that name is already in your workspace, this code will skip the creation process.\n",
    "\n",
    "As with other Azure services, there are limits on certain resources (e.g. AmlCompute) associated with the Azure Machine Learning service. Please read [this article](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-manage-quotas) on the default limits and how to request more quota."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target.\n",
      "{'allocationState': 'Steady', 'allocationStateTransitionTime': '2019-02-22T02:20:53.723000+00:00', 'creationTime': '2019-02-22T01:18:20.614322+00:00', 'currentNodeCount': 2, 'errors': None, 'modifiedTime': '2019-02-22T01:19:24.109719+00:00', 'nodeStateCounts': {'idleNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0, 'preparingNodeCount': 0, 'runningNodeCount': 2, 'unusableNodeCount': 0}, 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 2, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'targetNodeCount': 2, 'vmPriority': 'LowPriority', 'vmSize': 'STANDARD_NC6'}\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# choose a name for your cluster\n",
    "cluster_name = \"gpucluster\"\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing compute target.')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_NC6s_v3', \n",
    "                                                           max_nodes=4)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "    compute_target.wait_for_completion(show_output=True)\n",
    "\n",
    "# use get_status() to get a detailed status for the current cluster. \n",
    "print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code creates a GPU cluster. If you instead want to create a CPU cluster, provide a different VM size to the `vm_size` parameter, such as `STANDARD_D2_V2`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## リモート環境でのモデル開発\n",
    "Now that you have your data and training script prepared, you are ready to train on your remote compute cluster. You can take advantage of Azure compute to leverage GPUs to cut down your training time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### プロジェクトフォルダの作成\n",
    "Create a directory that will contain all the necessary code from your local machine that you will need access to on the remote resource. This includes the training script and any additional files your training script depends on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "project_folder = './chainer-mnist'\n",
    "os.makedirs(project_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習スクリプトの準備\n",
    "Now you will need to create your training script. In this tutorial, the training script is already provided for you at `chainer_mnist_hd.py`. In practice, you should be able to take any custom training script as is and run it with Azure ML without having to modify your code.\n",
    "\n",
    "However, if you would like to use Azure ML's [tracking and metrics](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#metrics) capabilities, you will have to add a small amount of Azure ML code inside your training script. \n",
    "\n",
    "In `chainer_mnist_hd.py`, we will log some metrics to our Azure ML run. To do so, we will access the Azure ML `Run` object within the script:\n",
    "```Python\n",
    "from azureml.core.run import Run\n",
    "run = Run.get_context()\n",
    "```\n",
    "Further within `chainer_mnist_hd.py`, we log the batchsize and epochs parameters, and the highest accuracy the model achieves:\n",
    "```Python\n",
    "run.log('Batch size', np.int(args.batchsize))\n",
    "run.log('Epochs', np.int(args.epochs))\n",
    "\n",
    "run.log('Accuracy', np.float(val_accuracy))\n",
    "```\n",
    "These run metrics will become particularly important when we begin hyperparameter tuning our model in the \"Tune model hyperparameters\" section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once your script is ready, copy the training script `chainer_mnist_hd.py` into your project directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./chainer-mnist/chainer_mnist.py'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.copy('chainer_mnist.py', project_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment \"実験\" の作成\n",
    "[Experiment\"実験\"](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#experiment) を作成し、Chainerによるモデル学習をトラックします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment_name = 'chainer-mnist-remote'\n",
    "experiment = Experiment(ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chainer estimator の作成\n",
    "The Azure ML SDK's Chainer estimator enables you to easily submit Chainer training jobs for both single-node and distributed runs. The following code will define a single-node Chainer job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.dnn import Chainer\n",
    "\n",
    "script_params = {\n",
    "    '--epochs': 10,\n",
    "    '--batchsize': 128,\n",
    "    '--output_dir': './outputs'\n",
    "}\n",
    "\n",
    "estimator = Chainer(source_directory=project_folder, \n",
    "                    script_params=script_params,\n",
    "                    compute_target=compute_target,\n",
    "                    pip_packages=['numpy', 'pytest','cupy-cuda90'],\n",
    "                    entry_script='chainer_mnist.py',\n",
    "                    use_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `script_params` parameter is a dictionary containing the command-line arguments to your training script `entry_script`. To leverage the Azure VM's GPU for training, we set `use_gpu=True`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ジョブの実行\n",
    "Run your experiment by submitting your estimator object. Note that this call is asynchronous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = experiment.submit(estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run のモニタリング\n",
    "You can monitor the progress of the run with a Jupyter widget. Like the run submission, the widget is asynchronous and provides live updates every 10-15 seconds until the job completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae7cc0f44e8246579d6b7b0875ac6e0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': True, 'log_level': 'INFO', 's…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: chainer-mnist-remote_1550802908_3644a0b1\n",
      "\n",
      "Streaming azureml-logs/60_control_log.txt\n",
      "=========================================\n",
      "\n",
      "Streaming log file azureml-logs/60_control_log.txt\n",
      "\n",
      "Streaming azureml-logs/80_driver_log.txt\n",
      "========================================\n",
      "\n",
      "Downloading from http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz...\n",
      "Downloading from http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz...\n",
      "Downloading from http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz...\n",
      "Downloading from http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz...\n",
      "epoch:01 train_loss:0.2911 val_loss:0.2650 val_accuracy:0.9226\n",
      "epoch:02 train_loss:0.1974 val_loss:0.1865 val_accuracy:0.9450\n",
      "epoch:03 train_loss:0.1718 val_loss:0.1581 val_accuracy:0.9522\n",
      "epoch:04 train_loss:0.1350 val_loss:0.1396 val_accuracy:0.9562\n",
      "epoch:05 train_loss:0.1398 val_loss:0.1177 val_accuracy:0.9639\n",
      "epoch:06 train_loss:0.1115 val_loss:0.1053 val_accuracy:0.9690\n",
      "epoch:07 train_loss:0.0660 val_loss:0.1013 val_accuracy:0.9694\n",
      "epoch:08 train_loss:0.0913 val_loss:0.0958 val_accuracy:0.9703\n",
      "epoch:09 train_loss:0.0331 val_loss:0.0925 val_accuracy:0.9718\n",
      "epoch:10 train_loss:0.0531 val_loss:0.0849 val_accuracy:0.9741\n",
      "\n",
      "\n",
      "The experiment completed successfully. Finalizing run...\n",
      "Logging experiment finalizing status in history service\n",
      "Cleaning up all outstanding Run operations, waiting 300.0 seconds\n",
      "2 items cleaning up...\n",
      "Cleanup took 0.20214009284973145 seconds\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: chainer-mnist-remote_1550802908_3644a0b1\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'chainer-mnist-remote_1550802908_3644a0b1',\n",
       " 'target': 'gpucluster',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2019-02-22T02:44:29.083393Z',\n",
       " 'endTimeUtc': '2019-02-22T02:47:01.678075Z',\n",
       " 'properties': {'azureml.runsource': 'experiment',\n",
       "  'ContentSnapshotId': '436df501-502e-4150-952c-c6b6376aed54'},\n",
       " 'runDefinition': {'Script': 'chainer_mnist.py',\n",
       "  'Arguments': ['--epochs',\n",
       "   '10',\n",
       "   '--batchsize',\n",
       "   '128',\n",
       "   '--output_dir',\n",
       "   './outputs'],\n",
       "  'SourceDirectoryDataStore': None,\n",
       "  'Framework': 0,\n",
       "  'Communicator': 0,\n",
       "  'Target': 'gpucluster',\n",
       "  'DataReferences': {},\n",
       "  'JobName': None,\n",
       "  'AutoPrepareEnvironment': True,\n",
       "  'MaxRunDurationSeconds': None,\n",
       "  'NodeCount': 1,\n",
       "  'Environment': {'Python': {'InterpreterPath': 'python',\n",
       "    'UserManagedDependencies': False,\n",
       "    'CondaDependencies': {'name': 'project_environment',\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults',\n",
       "        'chainer==5.1.0',\n",
       "        'numpy',\n",
       "        'pytest',\n",
       "        'cupy-cuda90']}]}},\n",
       "   'EnvironmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE',\n",
       "    'NCCL_SOCKET_IFNAME': '^docker0'},\n",
       "   'Docker': {'BaseImage': 'mcr.microsoft.com/azureml/base-gpu:0.2.1',\n",
       "    'Enabled': True,\n",
       "    'SharedVolumes': True,\n",
       "    'Preparation': None,\n",
       "    'GpuSupport': True,\n",
       "    'ShmSize': '1g',\n",
       "    'Arguments': [],\n",
       "    'BaseImageRegistry': {'Address': None,\n",
       "     'Username': None,\n",
       "     'Password': None}},\n",
       "   'Spark': {'Repositories': ['https://mmlspark.azureedge.net/maven'],\n",
       "    'Packages': [{'Group': 'com.microsoft.ml.spark',\n",
       "      'Artifact': 'mmlspark_2.11',\n",
       "      'Version': '0.12'}],\n",
       "    'PrecachePackages': True}},\n",
       "  'History': {'OutputCollection': True},\n",
       "  'Spark': {'Configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'BatchAi': {'NodeCount': 0},\n",
       "  'AmlCompute': {'Name': None,\n",
       "   'VmSize': None,\n",
       "   'VmPriority': None,\n",
       "   'RetainCluster': False,\n",
       "   'ClusterMaxNodeCount': 1},\n",
       "  'Tensorflow': {'WorkerCount': 1, 'ParameterServerCount': 1},\n",
       "  'Mpi': {'ProcessCountPerNode': 1},\n",
       "  'Hdi': {'YarnDeployMode': 2},\n",
       "  'ContainerInstance': {'Region': None, 'CpuCores': 2, 'MemoryGb': 3.5},\n",
       "  'ExposedPorts': None,\n",
       "  'PrepareEnvironment': None},\n",
       " 'logFiles': {'azureml-logs/60_control_log.txt': 'https://azureml5807231788.blob.core.windows.net/azureml/ExperimentRun/dcid.chainer-mnist-remote_1550802908_3644a0b1/azureml-logs/60_control_log.txt?sv=2018-03-28&sr=b&sig=xJ2K4BtzmBpikyWivVtYrag%2BhM4ZpK0IG9PqMGH1qUY%3D&st=2019-02-22T02%3A37%3A04Z&se=2019-02-22T10%3A47%3A04Z&sp=r',\n",
       "  'azureml-logs/80_driver_log.txt': 'https://azureml5807231788.blob.core.windows.net/azureml/ExperimentRun/dcid.chainer-mnist-remote_1550802908_3644a0b1/azureml-logs/80_driver_log.txt?sv=2018-03-28&sr=b&sig=JJ3SGU3CD34zIoOp6mq8iDus9MXjGBZt1Udvu1k8AWc%3D&st=2019-02-22T02%3A37%3A04Z&se=2019-02-22T10%3A47%3A04Z&sp=r',\n",
       "  'azureml-logs/azureml.log': 'https://azureml5807231788.blob.core.windows.net/azureml/ExperimentRun/dcid.chainer-mnist-remote_1550802908_3644a0b1/azureml-logs/azureml.log?sv=2018-03-28&sr=b&sig=MCKRK2HsX2Nj6%2BF2ZitqiGxXbTQgcM%2B3jol8yiKK%2Fkg%3D&st=2019-02-22T02%3A37%3A04Z&se=2019-02-22T10%3A47%3A04Z&sp=r',\n",
       "  'azureml-logs/55_batchai_execution.txt': 'https://azureml5807231788.blob.core.windows.net/azureml/ExperimentRun/dcid.chainer-mnist-remote_1550802908_3644a0b1/azureml-logs/55_batchai_execution.txt?sv=2018-03-28&sr=b&sig=EgaYwXWcbHQrJ6kRZc3v6727%2FSK8AEmnCrOronWAGHc%3D&st=2019-02-22T02%3A37%3A04Z&se=2019-02-22T10%3A47%3A04Z&sp=r'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "minxia"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "msauthor": "minxia"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

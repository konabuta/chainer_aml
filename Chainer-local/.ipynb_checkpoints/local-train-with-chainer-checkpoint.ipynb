{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chainer ローカル環境での学習\n",
    "\n",
    "本チュートリアルでは、Azure Machine Learning service Python SDK を利用して、Chainerでのモデル学習をローカル環境で実行します。学習におけるメトリックをクラウドに記録・共有いたします。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python SDK バージョン確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.0.18\n"
     ]
    }
   ],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ワークスペースへの接続\n",
    "Azure Machine Learning service の [ワークスペース](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspace) に接続します。Azureに対する認証が必要になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: azureml\n",
      "Azure region: eastus\n",
      "Subscription id: 9c0f91b8-eb2f-484c-979c-15848c098a6b\n",
      "Resource group: dllab\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "\n",
    "ws = Workspace.get(name='azureml', \n",
    "                      subscription_id='9c0f91b8-eb2f-484c-979c-15848c098a6b', \n",
    "                      resource_group='dllab'\n",
    "                   )\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ローカル環境でのモデル学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment \"実験\" の作成\n",
    "[Experiment\"実験\"](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#experiment) を作成し、Chainerによるモデル学習をトラックします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment_name = 'chainer-mnist-local'\n",
    "experiment = Experiment(ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = experiment.start_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデル学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'chainer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ffccf392e4e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mchainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchainer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'chainer'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import chainer\n",
    "from chainer import backends\n",
    "from chainer.backends import cuda\n",
    "from chainer import Function, gradient_check, report, training, utils, Variable\n",
    "from chainer import datasets, iterators, optimizers, serializers\n",
    "from chainer import Link, Chain, ChainList\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer.training import extensions\n",
    "from chainer.dataset import concat_examples\n",
    "from chainer.backends.cuda import to_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNetwork(Chain):\n",
    "\n",
    "    def __init__(self, n_mid_units=100, n_out=10):\n",
    "        super(MyNetwork, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.l1 = L.Linear(None, n_mid_units)\n",
    "            self.l2 = L.Linear(n_mid_units, n_mid_units)\n",
    "            self.l3 = L.Linear(n_mid_units, n_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.l1(x))\n",
    "        h = F.relu(self.l2(h))\n",
    "        return self.l3(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the MNIST data if you haven't downloaded it yet\n",
    "train, test = datasets.mnist.get_mnist(withlabel=True, ndim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_id = -1\n",
    "batchsize = 10\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log('Batch size', np.int(batchsize))\n",
    "run.log('Epochs', np.int(epochs))\n",
    "\n",
    "train_iter = iterators.SerialIterator(train, batchsize)\n",
    "test_iter = iterators.SerialIterator(test, batchsize,\n",
    "                                     repeat=False, shuffle=False)\n",
    "\n",
    "model = MyNetwork()\n",
    "\n",
    "if gpu_id >= 0:\n",
    "    # Make a specified GPU current\n",
    "    chainer.backends.cuda.get_device_from_id(0).use()\n",
    "    model.to_gpu()  # Copy the model to the GPU\n",
    "\n",
    "# Choose an optimizer algorithm\n",
    "optimizer = optimizers.MomentumSGD(lr=0.01, momentum=0.9)\n",
    "\n",
    "# Give the optimizer a reference to the model so that it\n",
    "# can locate the model's parameters.\n",
    "optimizer.setup(model)\n",
    "\n",
    "while train_iter.epoch < epochs:\n",
    "    # ---------- One iteration of the training loop ----------\n",
    "    train_batch = train_iter.next()\n",
    "    image_train, target_train = concat_examples(train_batch, gpu_id)\n",
    "\n",
    "    # Calculate the prediction of the network\n",
    "    prediction_train = model(image_train)\n",
    "\n",
    "    # Calculate the loss with softmax_cross_entropy\n",
    "    loss = F.softmax_cross_entropy(prediction_train, target_train)\n",
    "\n",
    "    # Calculate the gradients in the network\n",
    "    model.cleargrads()\n",
    "    loss.backward()\n",
    "\n",
    "    # Update all the trainable parameters\n",
    "    optimizer.update()\n",
    "    # --------------------- until here ---------------------\n",
    "\n",
    "    # Check the validation accuracy of prediction after every epoch\n",
    "    if train_iter.is_new_epoch:  # If this iteration is the final iteration of the current epoch\n",
    "\n",
    "        # Display the training loss\n",
    "        print('epoch:{:02d} train_loss:{:.04f} '.format(\n",
    "            train_iter.epoch, float(to_cpu(loss.array))), end='')\n",
    "\n",
    "        test_losses = []\n",
    "        test_accuracies = []\n",
    "        while True:\n",
    "            test_batch = test_iter.next()\n",
    "            image_test, target_test = concat_examples(test_batch, gpu_id)\n",
    "\n",
    "            # Forward the test data\n",
    "            prediction_test = model(image_test)\n",
    "\n",
    "            # Calculate the loss\n",
    "            loss_test = F.softmax_cross_entropy(prediction_test, target_test)\n",
    "            test_losses.append(to_cpu(loss_test.array))\n",
    "\n",
    "            # Calculate the accuracy\n",
    "            accuracy = F.accuracy(prediction_test, target_test)\n",
    "            accuracy.to_cpu()\n",
    "            test_accuracies.append(accuracy.array)\n",
    "\n",
    "            if test_iter.is_new_epoch:\n",
    "                test_iter.epoch = 0\n",
    "                test_iter.current_position = 0\n",
    "                test_iter.is_new_epoch = False\n",
    "                test_iter._pushed_position = None\n",
    "                break\n",
    "\n",
    "        val_accuracy = np.mean(test_accuracies)\n",
    "        print('val_loss:{:.04f} val_accuracy:{:.04f}'.format(\n",
    "            np.mean(test_losses), val_accuracy))\n",
    "\n",
    "        run.log(\"Accuracy\", np.float(val_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get more details of your run\n",
    "print(run.get_details())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 結果確認"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azure Portal でメトリックの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "※画面イメージ\n",
    "<br>\n",
    "<img src = \"../images/chainer_local_portal.png\" width = 1000>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "minxia"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "msauthor": "minxia"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and hyperparameter tune with Chainer\n",
    "\n",
    "In this tutorial, we demonstrate how to use the Azure ML Python SDK to train a Convolutional Neural Network (CNN) on a single-node GPU with Chainer to perform handwritten digit recognition on the popular MNIST dataset. We will also demonstrate how to perform hyperparameter tuning of the model using Azure ML's HyperDrive service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure ML service Python SDK バージョン確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.0.15\n"
     ]
    }
   ],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ワークスペースへの接続\n",
    "Azure Machine Learning service の [ワークスペース](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspace) に接続します。Azureに対する認証が必要になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: azureml\n",
      "Azure region: eastus\n",
      "Subscription id: 9c0f91b8-eb2f-484c-979c-15848c098a6b\n",
      "Resource group: dllab\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "\n",
    "ws = Workspace.get(name='azureml', \n",
    "                      subscription_id='9c0f91b8-eb2f-484c-979c-15848c098a6b', \n",
    "                      resource_group='dllab'\n",
    "                   )\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計算環境 Machine Learning Compute (旧Batch AI) の新規作成 or 既存環境設定\n",
    "You will need to create a [compute target](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#compute-target) to execute your training script on. In this tutorial, you create an [Azure Batch AI](https://docs.microsoft.com/azure/batch-ai/overview) cluster as your training compute resource. This code creates a cluster for you if it does not already exist in your workspace.\n",
    "\n",
    "**Creation of the cluster takes approximately 5 minutes.** If the cluster is already in your workspace this code will skip the cluster creation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target.\n",
      "{'allocationState': 'Steady', 'allocationStateTransitionTime': '2019-02-22T02:20:53.723000+00:00', 'creationTime': '2019-02-22T01:18:20.614322+00:00', 'currentNodeCount': 2, 'errors': None, 'modifiedTime': '2019-02-22T01:19:24.109719+00:00', 'nodeStateCounts': {'idleNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0, 'preparingNodeCount': 0, 'runningNodeCount': 2, 'unusableNodeCount': 0}, 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 2, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'targetNodeCount': 2, 'vmPriority': 'LowPriority', 'vmSize': 'STANDARD_NC6'}\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# choose a name for your cluster\n",
    "cluster_name = \"gpucluster\"\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing compute target.')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_NC6s_v3', \n",
    "                                                           max_nodes=4)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "    compute_target.wait_for_completion(show_output=True)\n",
    "\n",
    "# use get_status() to get a detailed status for the current cluster. \n",
    "print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code creates a GPU cluster. If you instead want to create a CPU cluster, provide a different VM size to the `vm_size` parameter, such as `STANDARD_D2_V2`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## リモート環境でのモデル開発\n",
    "Now that we have the cluster ready to go, let's run our distributed training job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### プロジェクトフォルダの作成\n",
    "Create a directory that will contain all the necessary code from your local machine that you will need access to on the remote resource. This includes the training script and any additional files your training script depends on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "project_folder = './chainer-mnist'\n",
    "os.makedirs(project_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training script\n",
    "Now you will need to create your training script. In this tutorial, the training script is already provided for you at `chainer_mnist_hd.py`. In practice, you should be able to take any custom training script as is and run it with Azure ML without having to modify your code.\n",
    "\n",
    "However, if you would like to use Azure ML's [tracking and metrics](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#metrics) capabilities, you will have to add a small amount of Azure ML code inside your training script. \n",
    "\n",
    "In `chainer_mnist_hd.py`, we will log some metrics to our Azure ML run. To do so, we will access the Azure ML `Run` object within the script:\n",
    "```Python\n",
    "from azureml.core.run import Run\n",
    "run = Run.get_context()\n",
    "```\n",
    "Further within `chainer_mnist_hd.py`, we log the batchsize and epochs parameters, and the highest accuracy the model achieves:\n",
    "```Python\n",
    "run.log('Batch size', np.int(args.batchsize))\n",
    "run.log('Epochs', np.int(args.epochs))\n",
    "\n",
    "run.log('Accuracy', np.float(val_accuracy))\n",
    "```\n",
    "These run metrics will become particularly important when we begin hyperparameter tuning our model in the \"Tune model hyperparameters\" section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once your script is ready, copy the training script `chainer_mnist_hd.py` into your project directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./chainer-mnist/chainer_mnist.py'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.copy('chainer_mnist.py', project_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment \"実験\" の作成\n",
    "[Experiment\"実験\"](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#experiment) を作成し、Chainerによるモデル学習をトラックします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment_name = 'chainer-mnist-hyperdrive'\n",
    "experiment = Experiment(ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Chainer estimator\n",
    "The Azure ML SDK's Chainer estimator enables you to easily submit Chainer training jobs for both single-node and distributed runs. The following code will define a single-node Chainer job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.dnn import Chainer\n",
    "\n",
    "script_params = {\n",
    "    '--epochs': 10,\n",
    "    '--batchsize': 128,\n",
    "    '--output_dir': './outputs'\n",
    "}\n",
    "\n",
    "estimator = Chainer(source_directory=project_folder, \n",
    "                    script_params=script_params,\n",
    "                    compute_target=compute_target,\n",
    "                    pip_packages=['numpy', 'pytest','cupy-cuda90'],\n",
    "                    entry_script='chainer_mnist.py',\n",
    "                    use_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `script_params` parameter is a dictionary containing the command-line arguments to your training script `entry_script`. To leverage the Azure VM's GPU for training, we set `use_gpu=True`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ジョブの実行\n",
    "Run your experiment by submitting your estimator object. Note that this call is asynchronous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = experiment.submit(estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run のモニタリング\n",
    "You can monitor the progress of the run with a Jupyter widget. Like the run submission, the widget is asynchronous and provides live updates every 10-15 seconds until the job completes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 学習の経過の確認\n",
    "学習の実行には下記の4ステップがあります。\n",
    "\n",
    "1. 準備：Chainer Estimater で指定されたPython環境に合わせてdockerイメージが作成され、それがワークスペースのAzure Container Registryにアップロードされます。このステップはPython環境ごとに一度だけ起こります。（その後の実行のためにコンテナはキャッシュされます。）画像の作成とアップロードには約5分かかります。ジョブの準備中、ログは実行履歴にストリーミングされ、イメージ作成の進行状況を監視するために表示できます。\n",
    "\n",
    "\n",
    "2. スケーリング：計算をスケールアップする必要がある場合（つまり、バッチAIクラスターで現在実行可能な数より多くのノードを実行する必要がある場合）、クラスターは必要な数のノードを使用可能にするためにスケールアップを試みます。スケーリングは通常約5分かかります。\n",
    "\n",
    "\n",
    "3. 実行中：スクリプトフォルダ内のすべてのスクリプトがコンピューティングターゲットにアップロードされ、データストアがマウントまたはコピーされてentry_scriptが実行されます。ジョブの実行中は、stdoutと./logsフォルダが実行履歴にストリーミングされ、実行の進行状況を監視するために表示できます。\n",
    "\n",
    "\n",
    "4. 後処理：実行の./outputsフォルダが実行履歴にコピーされます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0602c20ee12f451ebdcd5ec45d3ef8a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': True, 'log_level': 'INFO', 's…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'runId': 'chainer-mnist-hyperdrive_1550802183_4804ba6b', 'target': 'gpucluster', 'status': 'Completed', 'startTimeUtc': '2019-02-22T02:37:18.765603Z', 'endTimeUtc': '2019-02-22T02:41:06.587261Z', 'properties': {'azureml.runsource': 'experiment', 'ContentSnapshotId': 'cf424da7-47b0-4dba-99c9-a4e47673edb5'}, 'runDefinition': {'Script': 'chainer_mnist.py', 'Arguments': ['--epochs', '10', '--batchsize', '128', '--output_dir', './outputs'], 'SourceDirectoryDataStore': None, 'Framework': 0, 'Communicator': 0, 'Target': 'gpucluster', 'DataReferences': {}, 'JobName': None, 'AutoPrepareEnvironment': True, 'MaxRunDurationSeconds': None, 'NodeCount': 1, 'Environment': {'Python': {'InterpreterPath': 'python', 'UserManagedDependencies': False, 'CondaDependencies': {'name': 'project_environment', 'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults', 'chainer==5.1.0', 'numpy', 'pytest', 'cupy-cuda90']}]}}, 'EnvironmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE', 'NCCL_SOCKET_IFNAME': '^docker0'}, 'Docker': {'BaseImage': 'mcr.microsoft.com/azureml/base-gpu:0.2.1', 'Enabled': True, 'SharedVolumes': True, 'Preparation': None, 'GpuSupport': True, 'ShmSize': '1g', 'Arguments': [], 'BaseImageRegistry': {'Address': None, 'Username': None, 'Password': None}}, 'Spark': {'Repositories': ['https://mmlspark.azureedge.net/maven'], 'Packages': [{'Group': 'com.microsoft.ml.spark', 'Artifact': 'mmlspark_2.11', 'Version': '0.12'}], 'PrecachePackages': True}}, 'History': {'OutputCollection': True}, 'Spark': {'Configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'BatchAi': {'NodeCount': 0}, 'AmlCompute': {'Name': None, 'VmSize': None, 'VmPriority': None, 'RetainCluster': False, 'ClusterMaxNodeCount': 1}, 'Tensorflow': {'WorkerCount': 1, 'ParameterServerCount': 1}, 'Mpi': {'ProcessCountPerNode': 1}, 'Hdi': {'YarnDeployMode': 2}, 'ContainerInstance': {'Region': None, 'CpuCores': 2, 'MemoryGb': 3.5}, 'ExposedPorts': None, 'PrepareEnvironment': None}, 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://azureml5807231788.blob.core.windows.net/azureml/ExperimentRun/dcid.chainer-mnist-hyperdrive_1550802183_4804ba6b/azureml-logs/20_image_build_log.txt?sv=2018-03-28&sr=b&sig=kErg90RCSKUAfrgQ3Pf9apQhOAPEzMlLyTEsazDz6hA%3D&st=2019-02-22T02%3A40%3A47Z&se=2019-02-22T10%3A50%3A47Z&sp=r', 'azureml-logs/60_control_log.txt': 'https://azureml5807231788.blob.core.windows.net/azureml/ExperimentRun/dcid.chainer-mnist-hyperdrive_1550802183_4804ba6b/azureml-logs/60_control_log.txt?sv=2018-03-28&sr=b&sig=gtnE174r9zLppBwcpk4BMqqPOyUCx6jHB1ctUjEqK8w%3D&st=2019-02-22T02%3A40%3A47Z&se=2019-02-22T10%3A50%3A47Z&sp=r', 'azureml-logs/80_driver_log.txt': 'https://azureml5807231788.blob.core.windows.net/azureml/ExperimentRun/dcid.chainer-mnist-hyperdrive_1550802183_4804ba6b/azureml-logs/80_driver_log.txt?sv=2018-03-28&sr=b&sig=F5QNxuPKX7wurj9JjmgirmyyoKKbHKlZhtKKp%2BPaK1A%3D&st=2019-02-22T02%3A40%3A47Z&se=2019-02-22T10%3A50%3A47Z&sp=r', 'azureml-logs/azureml.log': 'https://azureml5807231788.blob.core.windows.net/azureml/ExperimentRun/dcid.chainer-mnist-hyperdrive_1550802183_4804ba6b/azureml-logs/azureml.log?sv=2018-03-28&sr=b&sig=7zX6KoB3AmYQbKTY2J2p3WEBZuxFKyFUJ4O%2FHuOPavc%3D&st=2019-02-22T02%3A40%3A47Z&se=2019-02-22T10%3A50%3A47Z&sp=r', 'azureml-logs/55_batchai_execution.txt': 'https://azureml5807231788.blob.core.windows.net/azureml/ExperimentRun/dcid.chainer-mnist-hyperdrive_1550802183_4804ba6b/azureml-logs/55_batchai_execution.txt?sv=2018-03-28&sr=b&sig=uzIqU1YSsRBCGGG7fJaB6QnQ3FZ%2F5VuWTJ5LdoH00PI%3D&st=2019-02-22T02%3A40%3A47Z&se=2019-02-22T10%3A50%3A47Z&sp=r'}}\n"
     ]
    }
   ],
   "source": [
    "# to get more details of your run\n",
    "print(run.get_details())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ハイパーパラメータのチューニング\n",
    "Now that we've seen how to do a simple Chainer training run using the SDK, let's see if we can further improve the accuracy of our model. We can optimize our model's hyperparameters using Azure Machine Learning's hyperparameter tuning capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start a hyperparameter sweep\n",
    "First, we will define the hyperparameter space to sweep over. Let's tune the batch size and epochs parameters. In this example we will use random sampling to try different configuration sets of hyperparameters to maximize our primary metric, accuracy.\n",
    "\n",
    "Then, we specify the early termination policy to use to early terminate poorly performing runs. Here we use the `BanditPolicy`, which will terminate any run that doesn't fall within the slack factor of our primary evaluation metric. In this tutorial, we will apply this policy every epoch (since we report our `Accuracy` metric every epoch and `evaluation_interval=1`). Notice we will delay the first policy evaluation until after the first `3` epochs (`delay_evaluation=3`).\n",
    "Refer [here](https://docs.microsoft.com/azure/machine-learning/service/how-to-tune-hyperparameters#specify-an-early-termination-policy) for more information on the BanditPolicy and other policies available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.hyperdrive.runconfig import HyperDriveRunConfig\n",
    "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
    "from azureml.train.hyperdrive.policy import BanditPolicy\n",
    "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive.parameter_expressions import choice\n",
    "    \n",
    "\n",
    "param_sampling = RandomParameterSampling( {\n",
    "    \"--batchsize\": choice(128, 256),\n",
    "    \"--epochs\": choice(5, 10, 20, 40)\n",
    "    }\n",
    ")\n",
    "\n",
    "hyperdrive_run_config = HyperDriveRunConfig(estimator=estimator,\n",
    "                                            hyperparameter_sampling=param_sampling, \n",
    "                                            primary_metric_name='Accuracy',\n",
    "                                            primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
    "                                            max_total_runs=8,\n",
    "                                            max_concurrent_runs=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, lauch the hyperparameter tuning job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The same input parameter(s) are specified in estimator script params and HyperDrive parameter space. HyperDrive parameter space definition will override duplicate entries in estimator. ['--epochs', '--batchsize'] is the list of overridden parameter(s).\n"
     ]
    }
   ],
   "source": [
    "# start the HyperDrive run\n",
    "hyperdrive_run = experiment.submit(hyperdrive_run_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor HyperDrive runs\n",
    "You can monitor the progress of the runs with the following Jupyter widget. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1550fffbf0d2440caeb744918ebb563c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_HyperDriveWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': True, 'log_level': 'INFO',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RunDetails(hyperdrive_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: chainer-mnist-hyperdrive_1550802183_4804ba6b\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: chainer-mnist-hyperdrive_1550802183_4804ba6b\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'chainer-mnist-hyperdrive_1550802183_4804ba6b',\n",
       " 'target': 'gpucluster',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2019-02-22T02:37:18.765603Z',\n",
       " 'endTimeUtc': '2019-02-22T02:41:06.587261Z',\n",
       " 'properties': {'azureml.runsource': 'experiment',\n",
       "  'ContentSnapshotId': 'cf424da7-47b0-4dba-99c9-a4e47673edb5'},\n",
       " 'runDefinition': {'Script': 'chainer_mnist.py',\n",
       "  'Arguments': ['--epochs',\n",
       "   '10',\n",
       "   '--batchsize',\n",
       "   '128',\n",
       "   '--output_dir',\n",
       "   './outputs'],\n",
       "  'SourceDirectoryDataStore': None,\n",
       "  'Framework': 0,\n",
       "  'Communicator': 0,\n",
       "  'Target': 'gpucluster',\n",
       "  'DataReferences': {},\n",
       "  'JobName': None,\n",
       "  'AutoPrepareEnvironment': True,\n",
       "  'MaxRunDurationSeconds': None,\n",
       "  'NodeCount': 1,\n",
       "  'Environment': {'Python': {'InterpreterPath': 'python',\n",
       "    'UserManagedDependencies': False,\n",
       "    'CondaDependencies': {'name': 'project_environment',\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults',\n",
       "        'chainer==5.1.0',\n",
       "        'numpy',\n",
       "        'pytest',\n",
       "        'cupy-cuda90']}]}},\n",
       "   'EnvironmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE',\n",
       "    'NCCL_SOCKET_IFNAME': '^docker0'},\n",
       "   'Docker': {'BaseImage': 'mcr.microsoft.com/azureml/base-gpu:0.2.1',\n",
       "    'Enabled': True,\n",
       "    'SharedVolumes': True,\n",
       "    'Preparation': None,\n",
       "    'GpuSupport': True,\n",
       "    'ShmSize': '1g',\n",
       "    'Arguments': [],\n",
       "    'BaseImageRegistry': {'Address': None,\n",
       "     'Username': None,\n",
       "     'Password': None}},\n",
       "   'Spark': {'Repositories': ['https://mmlspark.azureedge.net/maven'],\n",
       "    'Packages': [{'Group': 'com.microsoft.ml.spark',\n",
       "      'Artifact': 'mmlspark_2.11',\n",
       "      'Version': '0.12'}],\n",
       "    'PrecachePackages': True}},\n",
       "  'History': {'OutputCollection': True},\n",
       "  'Spark': {'Configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'BatchAi': {'NodeCount': 0},\n",
       "  'AmlCompute': {'Name': None,\n",
       "   'VmSize': None,\n",
       "   'VmPriority': None,\n",
       "   'RetainCluster': False,\n",
       "   'ClusterMaxNodeCount': 1},\n",
       "  'Tensorflow': {'WorkerCount': 1, 'ParameterServerCount': 1},\n",
       "  'Mpi': {'ProcessCountPerNode': 1},\n",
       "  'Hdi': {'YarnDeployMode': 2},\n",
       "  'ContainerInstance': {'Region': None, 'CpuCores': 2, 'MemoryGb': 3.5},\n",
       "  'ExposedPorts': None,\n",
       "  'PrepareEnvironment': None},\n",
       " 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://azureml5807231788.blob.core.windows.net/azureml/ExperimentRun/dcid.chainer-mnist-hyperdrive_1550802183_4804ba6b/azureml-logs/20_image_build_log.txt?sv=2018-03-28&sr=b&sig=po1YJcXE%2B8vX6rUnXZ%2BNz3wYNS0N4wyJ3RF7LT3JwDg%3D&st=2019-02-22T02%3A40%3A54Z&se=2019-02-22T10%3A50%3A54Z&sp=r',\n",
       "  'azureml-logs/60_control_log.txt': 'https://azureml5807231788.blob.core.windows.net/azureml/ExperimentRun/dcid.chainer-mnist-hyperdrive_1550802183_4804ba6b/azureml-logs/60_control_log.txt?sv=2018-03-28&sr=b&sig=qvT4xAzIkYIt31SMhGNIplP9kZ%2FAuIPzlSvXUzMMmSU%3D&st=2019-02-22T02%3A40%3A54Z&se=2019-02-22T10%3A50%3A54Z&sp=r',\n",
       "  'azureml-logs/80_driver_log.txt': 'https://azureml5807231788.blob.core.windows.net/azureml/ExperimentRun/dcid.chainer-mnist-hyperdrive_1550802183_4804ba6b/azureml-logs/80_driver_log.txt?sv=2018-03-28&sr=b&sig=%2BysghZQPhjta%2F3OtgTuEK63dfeK9PcN3HgPxHdw8eH4%3D&st=2019-02-22T02%3A40%3A54Z&se=2019-02-22T10%3A50%3A54Z&sp=r',\n",
       "  'azureml-logs/azureml.log': 'https://azureml5807231788.blob.core.windows.net/azureml/ExperimentRun/dcid.chainer-mnist-hyperdrive_1550802183_4804ba6b/azureml-logs/azureml.log?sv=2018-03-28&sr=b&sig=GPUd6cpCWQhTuB9NbTKeBDDd%2B5A14DbqRAUWrClShZg%3D&st=2019-02-22T02%3A40%3A54Z&se=2019-02-22T10%3A50%3A54Z&sp=r',\n",
       "  'azureml-logs/55_batchai_execution.txt': 'https://azureml5807231788.blob.core.windows.net/azureml/ExperimentRun/dcid.chainer-mnist-hyperdrive_1550802183_4804ba6b/azureml-logs/55_batchai_execution.txt?sv=2018-03-28&sr=b&sig=yQ8c5MsrhMvr98xjEoE2DVqjtl2alhcuD771c93Vwok%3D&st=2019-02-22T02%3A40%3A54Z&se=2019-02-22T10%3A50%3A54Z&sp=r'}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "※画面出力例\n",
    "\n",
    "<img src = \"../images/chainer-hyperdrive1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "minxia"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "msauthor": "minxia"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

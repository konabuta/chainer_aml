{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datastoreを使用した ChainerMNによる分散学習\n",
    "In this tutorial, you will run a Chainer training example on the [MNIST](http://yann.lecun.com/exdb/mnist/) dataset using ChainerMN distributed training across a GPU cluster. Training data is uploaded during the notebook to Azure Blob storage and registered as \"Datastore\" in Azure Machine Learning service Workspace. You can use \"Datastore\" after this experiment to access to the data in Azure Blob storage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure ML service Python SDK バージョン確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.0.15\n"
     ]
    }
   ],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ワークスペースへの接続\n",
    "Azure Machine Learning service の [ワークスペース](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspace) に接続します。Azureに対する認証が必要になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Falling back to use azure cli credentials. This fall back to use azure cli credentials will be removed in the next release. \n",
      "Make sure your code doesn't require 'az login' to have happened before using azureml-sdk, except the case when you are specifying AzureCliAuthentication in azureml-sdk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: azureml\n",
      "Azure region: southeastasia\n",
      "Subscription id: 9c0f91b8-eb2f-484c-979c-15848c098a6b\n",
      "Resource group: amlservice\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "\n",
    "ws = Workspace.get(name='azureml', \n",
    "                      subscription_id='9c0f91b8-eb2f-484c-979c-15848c098a6b', \n",
    "                      resource_group='amlservice'\n",
    "                   )\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計算環境 Machine Learning Compute (旧Batch AI) の新規作成 or 既存環境設定\n",
    "You will need to create a [compute target](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#compute-target) to execute your training script on. In this tutorial, you create an [Azure Batch AI](https://docs.microsoft.com/azure/batch-ai/overview) cluster as your training compute resource. This code creates a cluster for you if it does not already exist in your workspace.\n",
    "\n",
    "**Creation of the cluster takes approximately 5 minutes.** If the cluster is already in your workspace this code will skip the cluster creation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target gpu-ib\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "batchai_cluster_name = \"gpu-ib\"\n",
    "vm_size = \"Standard_NC24rs_v3\"\n",
    "\n",
    "try:\n",
    "    # Check for existing cluster\n",
    "    compute_target = ComputeTarget(ws,batchai_cluster_name)\n",
    "    print('Found existing compute target ' + batchai_cluster_name)\n",
    "except:\n",
    "    # Else, create new one\n",
    "    print('Creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = vm_size,\n",
    "                                                                    vm_priority = \"lowpriority\",\n",
    "                                                                    min_nodes = 0, \n",
    "                                                                    max_nodes = 2)\n",
    "    compute_target = ComputeTarget.create(ws, batchai_cluster_name, provisioning_config)\n",
    "    # can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it will use the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code creates GPU compute. If you instead want to create CPU compute, provide a different VM size to the `vm_size` parameter, such as `STANDARD_D2_V2`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## リモート環境でのモデル開発\n",
    "Now that we have the cluster ready to go, let's run our distributed training job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### プロジェクトフォルダの作成\n",
    "Create a directory that will contain all the necessary code from your local machine that you will need access to on the remote resource. This includes the training script and any additional files your training script depends on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "project_folder = './chainer-distr'\n",
    "os.makedirs(project_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training script\n",
    "Now you will need to create your training script. In this tutorial, the script for distributed training of MNIST is already provided for you at `train_mnist.py`. In practice, you should be able to take any custom Chainer training script as is and run it with Azure ML without having to modify your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once your script is ready, copy the training script `train_mnist.py` into the project directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./chainer-distr/chainer_mnist.py'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.copy('chainer_mnist.py', project_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習データのダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./data/mnist/test-labels.gz', <http.client.HTTPMessage at 0x1107c23c8>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib\n",
    "import os\n",
    "\n",
    "os.makedirs('./data/mnist', exist_ok=True)\n",
    "\n",
    "urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz', filename='./data/mnist/train-images.gz')\n",
    "urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz', filename='./data/mnist/train-labels.gz')\n",
    "urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz', filename='./data/mnist/test-images.gz')\n",
    "urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz', filename='./data/mnist/test-labels.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習データをデフォルトのDatastoreに保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ws.get_default_datastore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading ./data/mnist/test-images.gz\n",
      "Uploading ./data/mnist/test-labels.gz\n",
      "Uploading ./data/mnist/train-images.gz\n",
      "Uploading ./data/mnist/train-labels.gz\n",
      "Uploaded ./data/mnist/test-labels.gz, 1 files out of an estimated total of 4\n",
      "Uploaded ./data/mnist/train-labels.gz, 2 files out of an estimated total of 4\n",
      "Uploaded ./data/mnist/test-images.gz, 3 files out of an estimated total of 4\n",
      "Uploaded ./data/mnist/train-images.gz, 4 files out of an estimated total of 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_b1e0484842cd493298b559ef7498318b"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.upload(src_dir='./data/mnist', target_path='mnist', overwrite=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Azure Portal もしくは、Storage ExplorerなどのツールからBlobにデータがアップロードされていることを確認します。\n",
    "\n",
    "\n",
    "\n",
    "<div align=\"left\"><img src= \"../images/defaultblob.png\" width=\"500\" align =\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment \"実験\" の作成\n",
    "[Experiment\"実験\"](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#experiment) を作成し、Chainerによるモデル学習をトラックします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment_name = 'chainer-IB'\n",
    "experiment = Experiment(ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Chainer estimator\n",
    "The Azure ML SDK's Chainer estimator enables you to easily submit Chainer training jobs for both single-node and distributed runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.dnn import Chainer\n",
    "\n",
    "script_params = {\n",
    "    '-d': ds.path('mnist').as_mount(),\n",
    "    '-g': '',\n",
    "    '--communicator': 'non_cuda_aware',\n",
    "    '-o': './outputs'\n",
    "}\n",
    "\n",
    "estimator = Chainer(source_directory=project_folder,\n",
    "                      compute_target=compute_target,\n",
    "                      entry_script='chainer_mnist.py',\n",
    "                      script_params=script_params,\n",
    "                      node_count=2,\n",
    "                      process_count_per_node=2,\n",
    "                      distributed_backend='mpi',     \n",
    "                      pip_packages=['mpi4py','pytest'],\n",
    "                      use_gpu=True)\n",
    " \n",
    "# 次期バージョンで削除予定\n",
    "estimator.run_config.environment.environment_variables['NCCL_SOCKET_IFNAME'] = 'eth0'\n",
    "estimator.run_config.environment.environment_variables['NCCL_IB_DISABLE'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code specifies that we will run our training script on `2` nodes, with one worker per node. In order to execute a distributed run using MPI, you must provide the argument `distributed_backend='mpi'`. Using this estimator with these settings, Chainer and its dependencies will be installed for you. However, if your script also uses other packages, make sure to install them via the `Chainer` constructor's `pip_packages` or `conda_packages` parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ジョブの実行\n",
    "Run your experiment by submitting your estimator object. Note that this call is asynchronous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(Experiment: chainer-IB,\n",
      "Id: chainer-IB_1550835911_6efafd06,\n",
      "Type: azureml.scriptrun,\n",
      "Status: Queued)\n"
     ]
    }
   ],
   "source": [
    "run = experiment.submit(estimator)\n",
    "print(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run のモニタリング\n",
    "You can monitor the progress of the run with a Jupyter widget. Like the run submission, the widget is asynchronous and provides live updates every 10-15 seconds until the job completes. You can see that the widget automatically plots and visualizes the loss metric that we logged to the Azure ML run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 学習の経過の確認\n",
    "学習の実行には下記の4ステップがあります。\n",
    "\n",
    "1. 準備：Chainer Estimater で指定されたPython環境に合わせてdockerイメージが作成され、それがワークスペースのAzure Container Registryにアップロードされます。このステップはPython環境ごとに一度だけ起こります。（その後の実行のためにコンテナはキャッシュされます。）画像の作成とアップロードには約5分かかります。ジョブの準備中、ログは実行履歴にストリーミングされ、イメージ作成の進行状況を監視するために表示できます。\n",
    "\n",
    "\n",
    "2. スケーリング：計算をスケールアップする必要がある場合（つまり、バッチAIクラスターで現在実行可能な数より多くのノードを実行する必要がある場合）、クラスターは必要な数のノードを使用可能にするためにスケールアップを試みます。スケーリングは通常約5分かかります。\n",
    "\n",
    "\n",
    "3. 実行中：スクリプトフォルダ内のすべてのスクリプトがコンピューティングターゲットにアップロードされ、データストアがマウントまたはコピーされてentry_scriptが実行されます。ジョブの実行中は、stdoutと./logsフォルダが実行履歴にストリーミングされ、実行の進行状況を監視するために表示できます。\n",
    "\n",
    "\n",
    "4. 後処理：実行の./outputsフォルダが実行履歴にコピーされます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0385a790a32490eb56f733c48caf44b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': True, 'log_level': 'INFO', 's…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: chainer-IB_1550835911_6efafd06\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: chainer-IB_1550835911_6efafd06\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'chainer-IB_1550835911_6efafd06',\n",
       " 'target': 'gpu-ib',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2019-02-22T11:45:30.278196Z',\n",
       " 'endTimeUtc': '2019-02-22T11:49:35.247704Z',\n",
       " 'properties': {'azureml.runsource': 'experiment',\n",
       "  'ContentSnapshotId': 'c682a49b-96ce-4e9d-ab08-651809604f2f'},\n",
       " 'runDefinition': {'Script': 'chainer_mnist.py',\n",
       "  'Arguments': ['-d',\n",
       "   '$AZUREML_DATAREFERENCE_e5a77aac900b4293ac6f791fa457b1b3',\n",
       "   '-g',\n",
       "   '--communicator',\n",
       "   'non_cuda_aware',\n",
       "   '-o',\n",
       "   './outputs'],\n",
       "  'SourceDirectoryDataStore': 'workspaceblobstore',\n",
       "  'Framework': 0,\n",
       "  'Communicator': 5,\n",
       "  'Target': 'gpu-ib',\n",
       "  'DataReferences': {'e5a77aac900b4293ac6f791fa457b1b3': {'DataStoreName': 'workspaceblobstore',\n",
       "    'Mode': 'Mount',\n",
       "    'PathOnDataStore': 'mnist',\n",
       "    'PathOnCompute': None,\n",
       "    'Overwrite': False},\n",
       "   'workspaceblobstore': {'DataStoreName': 'workspaceblobstore',\n",
       "    'Mode': 'Mount',\n",
       "    'PathOnDataStore': None,\n",
       "    'PathOnCompute': None,\n",
       "    'Overwrite': False}},\n",
       "  'JobName': None,\n",
       "  'AutoPrepareEnvironment': True,\n",
       "  'MaxRunDurationSeconds': None,\n",
       "  'NodeCount': 2,\n",
       "  'Environment': {'Python': {'InterpreterPath': 'python',\n",
       "    'UserManagedDependencies': False,\n",
       "    'CondaDependencies': {'name': 'project_environment',\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults',\n",
       "        'chainer==5.1.0',\n",
       "        'cupy-cuda90',\n",
       "        'mpi4py',\n",
       "        'pytest']}]}},\n",
       "   'EnvironmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE',\n",
       "    'NCCL_SOCKET_IFNAME': 'eth0',\n",
       "    'NCCL_IB_DISABLE': '1'},\n",
       "   'Docker': {'BaseImage': 'mcr.microsoft.com/azureml/base-gpu:0.2.1',\n",
       "    'Enabled': True,\n",
       "    'SharedVolumes': True,\n",
       "    'Preparation': None,\n",
       "    'GpuSupport': True,\n",
       "    'ShmSize': '1g',\n",
       "    'Arguments': [],\n",
       "    'BaseImageRegistry': {'Address': None,\n",
       "     'Username': None,\n",
       "     'Password': None}},\n",
       "   'Spark': {'Repositories': ['https://mmlspark.azureedge.net/maven'],\n",
       "    'Packages': [{'Group': 'com.microsoft.ml.spark',\n",
       "      'Artifact': 'mmlspark_2.11',\n",
       "      'Version': '0.12'}],\n",
       "    'PrecachePackages': True}},\n",
       "  'History': {'OutputCollection': True},\n",
       "  'Spark': {'Configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'BatchAi': {'NodeCount': 0},\n",
       "  'AmlCompute': {'Name': None,\n",
       "   'VmSize': None,\n",
       "   'VmPriority': None,\n",
       "   'RetainCluster': False,\n",
       "   'ClusterMaxNodeCount': 2},\n",
       "  'Tensorflow': {'WorkerCount': 1, 'ParameterServerCount': 1},\n",
       "  'Mpi': {'ProcessCountPerNode': 2},\n",
       "  'Hdi': {'YarnDeployMode': 2},\n",
       "  'ContainerInstance': {'Region': None, 'CpuCores': 2, 'MemoryGb': 3.5},\n",
       "  'ExposedPorts': None,\n",
       "  'PrepareEnvironment': None},\n",
       " 'logFiles': {'azureml-logs/60_control_log_rank_0.txt': 'https://azureml7674401039.blob.core.windows.net/azureml/ExperimentRun/dcid.chainer-IB_1550835911_6efafd06/azureml-logs/60_control_log_rank_0.txt?sv=2018-03-28&sr=b&sig=4XrpkPEUskjdX%2BX6ZmhNRAPWAGgGApWeFS5U4SIa55Q%3D&st=2019-02-22T11%3A53%3A04Z&se=2019-02-22T20%3A03%3A04Z&sp=r',\n",
       "  'azureml-logs/60_control_log_rank_3.txt': 'https://azureml7674401039.blob.core.windows.net/azureml/ExperimentRun/dcid.chainer-IB_1550835911_6efafd06/azureml-logs/60_control_log_rank_3.txt?sv=2018-03-28&sr=b&sig=sZbOPcSegUtCpVuJaj6n6LFjIfJ7fUlj2ZCUSDDSHmM%3D&st=2019-02-22T11%3A53%3A04Z&se=2019-02-22T20%3A03%3A04Z&sp=r',\n",
       "  'azureml-logs/60_control_log_rank_1.txt': 'https://azureml7674401039.blob.core.windows.net/azureml/ExperimentRun/dcid.chainer-IB_1550835911_6efafd06/azureml-logs/60_control_log_rank_1.txt?sv=2018-03-28&sr=b&sig=k597rwxBHHZyuuXQg28I%2BoZoE8yYJkcX%2FCA6hUyUSz0%3D&st=2019-02-22T11%3A53%3A04Z&se=2019-02-22T20%3A03%3A04Z&sp=r',\n",
       "  'azureml-logs/60_control_log_rank_2.txt': 'https://azureml7674401039.blob.core.windows.net/azureml/ExperimentRun/dcid.chainer-IB_1550835911_6efafd06/azureml-logs/60_control_log_rank_2.txt?sv=2018-03-28&sr=b&sig=%2FUNF7Zkoit5GiCmYxVFQin7icgRk5wubKn9ObPfN6J8%3D&st=2019-02-22T11%3A53%3A04Z&se=2019-02-22T20%3A03%3A04Z&sp=r',\n",
       "  'azureml-logs/80_driver_log_rank_0.txt': 'https://azureml7674401039.blob.core.windows.net/azureml/ExperimentRun/dcid.chainer-IB_1550835911_6efafd06/azureml-logs/80_driver_log_rank_0.txt?sv=2018-03-28&sr=b&sig=AiG1V%2Bzqxz1yLR0or4ioix0s8ZsXm4z5DV0RfP9Jlrg%3D&st=2019-02-22T11%3A53%3A04Z&se=2019-02-22T20%3A03%3A04Z&sp=r',\n",
       "  'azureml-logs/80_driver_log_rank_1.txt': 'https://azureml7674401039.blob.core.windows.net/azureml/ExperimentRun/dcid.chainer-IB_1550835911_6efafd06/azureml-logs/80_driver_log_rank_1.txt?sv=2018-03-28&sr=b&sig=X%2BZcF7jF%2Bdg5dO0U1nBGMA5Wn9qtx8tKJ3Yk43yz0BU%3D&st=2019-02-22T11%3A53%3A04Z&se=2019-02-22T20%3A03%3A04Z&sp=r',\n",
       "  'azureml-logs/80_driver_log_rank_2.txt': 'https://azureml7674401039.blob.core.windows.net/azureml/ExperimentRun/dcid.chainer-IB_1550835911_6efafd06/azureml-logs/80_driver_log_rank_2.txt?sv=2018-03-28&sr=b&sig=20iMOE5VfPfTX5BX5BBHZuHFr6y%2F6Ceht3WMTzeTJ0U%3D&st=2019-02-22T11%3A53%3A04Z&se=2019-02-22T20%3A03%3A04Z&sp=r',\n",
       "  'azureml-logs/80_driver_log_rank_3.txt': 'https://azureml7674401039.blob.core.windows.net/azureml/ExperimentRun/dcid.chainer-IB_1550835911_6efafd06/azureml-logs/80_driver_log_rank_3.txt?sv=2018-03-28&sr=b&sig=TCS9%2BwB7L7PB6VFWulktc9P8vGeN841Sv6KouwxM33c%3D&st=2019-02-22T11%3A53%3A04Z&se=2019-02-22T20%3A03%3A04Z&sp=r',\n",
       "  'azureml-logs/azureml.log': 'https://azureml7674401039.blob.core.windows.net/azureml/ExperimentRun/dcid.chainer-IB_1550835911_6efafd06/azureml-logs/azureml.log?sv=2018-03-28&sr=b&sig=3EAmu6dDIuKEGMKIFMk55sjOYxAtFyKY4DS9LYTHP00%3D&st=2019-02-22T11%3A53%3A04Z&se=2019-02-22T20%3A03%3A04Z&sp=r',\n",
       "  'azureml-logs/56_batchai_stderr.txt': 'https://azureml7674401039.blob.core.windows.net/azureml/ExperimentRun/dcid.chainer-IB_1550835911_6efafd06/azureml-logs/56_batchai_stderr.txt?sv=2018-03-28&sr=b&sig=wup%2Bt25k31DBCJ5XbynMxQZ3f3UbBSMPg9h2dJkNsXo%3D&st=2019-02-22T11%3A53%3A04Z&se=2019-02-22T20%3A03%3A04Z&sp=r'}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "minxia"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "msauthor": "minxia"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
